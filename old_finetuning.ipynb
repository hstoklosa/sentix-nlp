{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgPUqN_Tn5gj"
      },
      "source": [
        "# Fine-tuning FinBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvl-OUKyoCt3",
        "outputId": "9b3873c1-ee52-4e30-959e-3dbecb5219b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TVoE1cGn5gl"
      },
      "source": [
        "## Load the libraries and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oRtWa2VEn5gl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "MODEL_NAME = \"ProsusAI/finbert\"\n",
        "EXPORT_DIR = \"./model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjBFeg5Qn5gm"
      },
      "source": [
        "## Load the model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xKHXOnFIn5gm"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s13VkTGzn5gn"
      },
      "source": [
        "## Load the preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "ZctVkKPbn5gn",
        "outputId": "c975a129-66b7-47e9-900d-511cf766b3e0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_sample\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"YouTube has doubled down on its future NFT plans claiming that it could make them safer upon launch.\\\\r\\\\n\",\n          \"Laura Mercurio will replace Steve Vallas as Blockchain Australia's next Chief Executive Officer from Monday (September 12).\",\n          \"The circulating supply of WLD tokens has steadily risen 1.34% of the 10 billion total supply.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13386560424545207,\n        \"min\": -0.08,\n        \"max\": 0.27,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.08,\n          0.0,\n          0.08\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subjectivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24464259645450137,\n        \"min\": 0.0,\n        \"max\": 0.62,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.21,\n          0.0,\n          0.62\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_sample"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-669723a6-77dd-41bd-ad5b-1101b7eee989\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>polarity</th>\n",
              "      <th>subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23951</th>\n",
              "      <td>Short-term hodlers may be done with the bulk o...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29515</th>\n",
              "      <td>YouTube has doubled down on its future NFT pla...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3035</th>\n",
              "      <td>The circulating supply of WLD tokens has stead...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27926</th>\n",
              "      <td>Grayscale’s new fund gives weighted exposure t...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21125</th>\n",
              "      <td>Laura Mercurio will replace Steve Vallas as Bl...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-669723a6-77dd-41bd-ad5b-1101b7eee989')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-669723a6-77dd-41bd-ad5b-1101b7eee989 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-669723a6-77dd-41bd-ad5b-1101b7eee989');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-29403b99-ee3a-4596-b6f6-8afedc00cfd3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29403b99-ee3a-4596-b6f6-8afedc00cfd3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-29403b99-ee3a-4596-b6f6-8afedc00cfd3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                    text  sentiment  polarity  \\\n",
              "23951  Short-term hodlers may be done with the bulk o...          2      0.27   \n",
              "29515  YouTube has doubled down on its future NFT pla...          0     -0.08   \n",
              "3035   The circulating supply of WLD tokens has stead...          2      0.08   \n",
              "27926  Grayscale’s new fund gives weighted exposure t...          2      0.14   \n",
              "21125  Laura Mercurio will replace Steve Vallas as Bl...          1      0.00   \n",
              "\n",
              "       subjectivity  \n",
              "23951          0.47  \n",
              "29515          0.21  \n",
              "3035           0.62  \n",
              "27926          0.45  \n",
              "21125          0.00  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df = pd.read_csv(\"data/preprocessed_cryptonews.csv\")\n",
        "# df = df.sample(1037)\n",
        "# df.head()\n",
        "\n",
        "absolute_path = \"/content/drive/My Drive/Colab Notebooks\"\n",
        "dataset_file_path = os.path.join(absolute_path, \"Datasets\", \"preprocessed_cryptonews.csv\")\n",
        "\n",
        "df = pd.read_csv(dataset_file_path)\n",
        "df_sample = df.sample(5)\n",
        "\n",
        "df_sample.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7voIAEmzn5go"
      },
      "source": [
        "## Tokenize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": true,
        "id": "vvihD-Vln5go"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TorchDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Create a PyTorch dataset for text classification using BERT models.\n",
        "    \"\"\"\n",
        "    def __init__(self, inputs, labels, max_length=512):\n",
        "        self.inputs = inputs\n",
        "        self.labels = labels\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "         # text, label = self.inputs[idx], self.labels[idx] # This line is not needed\n",
        "\n",
        "        # Convert input_ids and attention_mask to PyTorch tensors\n",
        "        input_ids = torch.tensor(self.inputs['input_ids'][idx], dtype=torch.long)\n",
        "        attention_mask = torch.tensor(self.inputs['attention_mask'][idx], dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "X_train, y_train = list(df_sample['text']), list(df_sample['sentiment'])\n",
        "X_train_encoded = tokenizer(\n",
        "    X_train,\n",
        "    truncation=True,\n",
        "    padding=True\n",
        ")\n",
        "dataloader = DataLoader(\n",
        "    TorchDataset(X_train_encoded, y_train),\n",
        "    batch_size=5,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-LdfsOFn5go"
      },
      "source": [
        "## Fine-tune the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neNoUriOn5go"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OnhQYRZon5gp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVmmVFwen5gp"
      },
      "source": [
        "### Inference\n",
        "\n",
        "Improving the performance of model inference:\n",
        "- Use batch processing through the `datasets` library which integrates well with PyTorch's `DataLoader` option.\n",
        "- If available, use move both the model and its inputs to the GPU to speed up the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zqCG219OByk",
        "outputId": "126f9b1b-f6a4-488d-c64d-dd08c92efc11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[np.int64(2), np.int64(2), np.int64(1), np.int64(2), np.int64(0)] [np.int64(2), np.int64(0), np.int64(2), np.int64(2), np.int64(2)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.4, 'precision': 0.3, 'recall': 0.4, 'f1': 0.34285714285714286}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "\n",
        "def compute_metrics(labels, preds, average='weighted'):\n",
        "    \"\"\"\n",
        "    Compute accuracy, precision, recall, and F1 score based on predictions.\n",
        "    \"\"\"\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average=average\n",
        "    )\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "def predict_sentiment(model, dataloader, batch_size=128):\n",
        "    # Enable evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    all_labels, all_predictions = [], []\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "            labels = inputs[\"labels\"]\n",
        "\n",
        "            # Get predictions for this batch\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Get probabilities for this batch\n",
        "            batch_probabilities = torch.softmax(logits, dim=1)\n",
        "            batch_classes = torch.argmax(batch_probabilities, dim=1)\n",
        "\n",
        "            # Add to aggregated results (move back to CPU for list conversion)\n",
        "            # all_predictions.extend(batch_classes.cpu().tolist())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(batch_classes.cpu().numpy())\n",
        "\n",
        "    return all_labels, all_predictions\n",
        "\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# Get predictions based on the loaded data\n",
        "labels, predictions = predict_sentiment(model, dataloader)\n",
        "print(labels, predictions)\n",
        "results = compute_metrics(labels, predictions)\n",
        "# results = compute_metrics(df['sentiment'], torch.tensor(predictions))\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUzPuFuSTqbw"
      },
      "source": [
        "## old inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "XlaInKWfn5gp",
        "outputId": "47f1b753-647f-4514-f6e9-01656aa23912"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ff0de1baffe9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mall_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ff0de1baffe9>\u001b[0m in \u001b[0;36mpredict_with_model\u001b[0;34m(model, encodings, batch_size)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# Add to aggregated results (move back to CPU for list conversion)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mall_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mall_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(preds, labels, average='weighted'):\n",
        "    \"\"\"\n",
        "    Compute accuracy, precision, recall, and F1 score based on predictions.\n",
        "    \"\"\"\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average=average\n",
        "    )\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "def predict_with_model(model, encodings, batch_size=128):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Move model to GPU if available\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = model.to(device)\n",
        "\n",
        "        input_ids = torch.tensor(encodings['input_ids'])\n",
        "        attention_mask = torch.tensor(encodings['attention_mask'])\n",
        "\n",
        "        # Create a DataLoader for batching\n",
        "        dataset = torch.utils.data.TensorDataset(input_ids, attention_mask)\n",
        "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
        "\n",
        "        all_predictions = []\n",
        "\n",
        "        for batch_input_ids, batch_attention_mask in dataloader:\n",
        "            # Move batch to GPU if available\n",
        "            batch_input_ids = batch_input_ids.to(device)\n",
        "            batch_attention_mask = batch_attention_mask.to(device)\n",
        "\n",
        "            # Get predictions for this batch\n",
        "            outputs = model(\n",
        "                input_ids=batch_input_ids,\n",
        "                attention_mask=batch_attention_mask\n",
        "            )\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Get probabilities for this batch\n",
        "            batch_probabilities = torch.softmax(logits, dim=1)\n",
        "            batch_classes = torch.argmax(batch_probabilities, dim=1)\n",
        "\n",
        "            # Add to aggregated results (move back to CPU for list conversion)\n",
        "            all_predictions.extend(batch_classes.cpu().tolist())\n",
        "\n",
        "        return all_predictions\n",
        "\n",
        "\n",
        "\n",
        "predictions = predict_with_model(model, encodings)\n",
        "results = compute_metrics(df['sentiment'], torch.tensor(predictions))\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcuiULTJn5gp"
      },
      "source": [
        "## Export outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHJXUG4Qn5gp",
        "outputId": "caae4bac-6591-4134-903c-facd9a375fd0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./model/tokenizer_config.json',\n",
              " './model/special_tokens_map.json',\n",
              " './model/vocab.txt',\n",
              " './model/added_tokens.json',\n",
              " './model/tokenizer.json')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(EXPORT_DIR)\n",
        "tokenizer.save_pretrained(EXPORT_DIR)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
