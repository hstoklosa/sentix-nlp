{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17vbESpwDeki"
      },
      "source": [
        " # Fine-tuning CryptoBERT Model + Hyperparameter Optimisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygTl9eH_Deku",
        "outputId": "035e5647-f88f-4bfa-bea9-e36ac1666dd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWHD01A-Dek0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# PATH CONSTANTS\n",
        "ABSOLUTE_PATH = \"/content/drive/My Drive/sentix_nlp\"\n",
        "PREPROCESSED_DATA_DIR = ABSOLUTE_PATH + \"/data/preprocessed\"\n",
        "EXPORT_MODEL_DIR = ABSOLUTE_PATH + \"/models\"\n",
        "\n",
        "sys.path.insert(0, ABSOLUTE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auC4hBUmDek0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b40e65a-8ccb-44b5-a6b4-b065a7ac70a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install --upgrade transformers optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq-jGoOSDek3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import optuna\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from optuna.pruners import MedianPruner\n",
        "from optuna.samplers import TPESampler\n",
        "from transformers import (\n",
        "  AutoModelForSequenceClassification,\n",
        "  AutoTokenizer,\n",
        "  Trainer,\n",
        "  TrainingArguments,\n",
        "  EvalPrediction\n",
        ")\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (\n",
        "  classification_report,\n",
        "  confusion_matrix,\n",
        "  ConfusionMatrixDisplay,\n",
        "  accuracy_score,\n",
        "  f1_score\n",
        ")\n",
        "from utils import NewsDataset, compute_metrics\n",
        "\n",
        "\n",
        "# MODEL CONSTANTS\n",
        "MODEL_NAME=\"ElKulako/cryptobert\"\n",
        "NUM_LABELS=3\n",
        "BATCH_SIZE=16\n",
        "NUM_EPOCHS= 3 #4\n",
        "LEARNING_RATE= 5e-5 #2e-5\n",
        "WEIGHT_DECAY=0.01\n",
        "WARMUP_RATIO=0.1\n",
        "WARMUP_STEPS=3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXAHAtU8Dek3"
      },
      "source": [
        " ## Load the model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onUV3VaBDek4"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,num_labels=NUM_LABELS\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2FhaRPCDek5"
      },
      "source": [
        " ### Switch to CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sXyONYKDek6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec596592-d263-4797-e045-6010ee9ceb0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKNuc3znDek6"
      },
      "source": [
        " ## Load the preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fpdHf_2Dek7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a1fb5051-39ee-4522-ab83-d25ff4776f09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           full_text  label\n",
              "0  singapore exchange to launch bitcoin perpetual...      2\n",
              "1  market madness continues – learn why hedera hb...      2\n",
              "2  cardano price forecast can ada rise 5000 a blo...      1\n",
              "3  when will cardano ada break the 1 barrier . ca...      0\n",
              "4  bitpanda secures micar license from austria ’ ...      2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7366cf12-4832-4dac-87fd-4b70f2d5e99c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>singapore exchange to launch bitcoin perpetual...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>market madness continues – learn why hedera hb...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cardano price forecast can ada rise 5000 a blo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>when will cardano ada break the 1 barrier . ca...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bitpanda secures micar license from austria ’ ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7366cf12-4832-4dac-87fd-4b70f2d5e99c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7366cf12-4832-4dac-87fd-4b70f2d5e99c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7366cf12-4832-4dac-87fd-4b70f2d5e99c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7fb0c7fb-e70e-49fa-84b4-7621b74294bf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7fb0c7fb-e70e-49fa-84b4-7621b74294bf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7fb0c7fb-e70e-49fa-84b4-7621b74294bf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 14945,\n  \"fields\": [\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14945,\n        \"samples\": [\n          \"dogecoin keep jumping between key support level meanwhile yetio touch 33m in presale acquisition . dogecoin doge price is under 020 a market capitalization of approximately 28 billion and is a decent distance from it alltime high of 073 while the prevailing market is more in the muskpopular doge favour the currency still reflects shaky trend for a range of reason while thats the case yeti ouro yetio hit 33 million in it abouttoconclude stage 3 presale purchase dogecoin price prediction doge keep floating in the murky water dogecoin price is oscillating in the range of major support and resistance level of 0137 0142 and 0160 0165 a a result it ha formed a downwardsfacing bear flag pattern which ha already gone beneath the initial doge support level and may return to major support shortly shortterm doge buy may be available at the moment or shortly after the daily candle close higher than the main resistance level with the launch of several upcoming exchangetraded fund etf proposal the onetime meme coin is heading toward increased adoption in the financial establishment 21shares ha filed a spot etf application supported by both the dogecoin foundation and coinbase bitwise ha also proposed it own application and grayscale is offering investment through the dogecoin trust which is aimed at institutional client if these doge etf are approved they may be able to draw considerable quantity of institutional investment with longterm arrangement that involve simpler process eliminating the use of digital wallet or outright management risk dogecoin price fell from 0169 to 0155 in four day a decrease of about 9 the price drop indicates that trader are selling during the recovery which is a negative sign for the outlook on the other hand big trader or whale are adding to their doge position analyst ali martinez reported that such trader picked up more than 800 million doge in 48 hour the action implies that educated trader are speculating doge \\u2019 s recovery while most retail trader panic yetio gear up for stage 4 presale yeti ouro yetio is a new crypto project that encapsulates meme coin charm with actual usability through it alignment with a playtoearn gaming platform the project ha already collected 33 million during this third presale stage and at the time of writing 215921824 token of yetio have been sold yetio is differentiated from other meme coin by it 1b token supply cap and deflationary tokenomics with 5 of yetio \\u2019 s supply set to be burned to drive token value higher a time pass the presale price is at the moment 0024token a 100 return for initial adopter who bought in at the stage 1 price of 0012 yeti ouro is turning up the heat this easter weekend with a limitedtime 30 bonus on all token purchase available now through tuesday april 22nd 2025 this exclusive offer come a stage 3 enters it final stretch\\u2014just 5 day remain with a confirmed steeper price increase ahead in stage 4 now is the ideal moment to stock up on token and stay ahead of the curve before the next phase begin further to this yeti ouro is calling on it community to get creative with a character design contest to shape the next ingame character the winning entry will be forever featured in the yeti go universe with the creator receiving full recognition and a 1000 reward in yetio token plus ten runnersup will each score 250 in token head over to yeti go \\u2019 s official x platform for all the entry detail yeti go\\u2014yetio \\u2019 s usp playtoearn creation yetios main value lie in yeti go a gokart game based on unreal engine 5 that support playtoearn p2e mechanism player are rewarded with yetio token when they complete mission and win tournament yeti go take immersive gaming to the next level combining breathtaking visuals with expertly crafted sound for an experience that \\u2019 s a cinematic a it is thrilling created in collaboration with the acclaimed studio behind legendary title like call of duty spiderman the witcher and dead space the game is built to impress from every angle it soundscape\\u2014shaped by audio specialist who \\u2019 ve worked with grammynominated artist including major lazer vybz kartel and kabaka pyramid\\u2014adds emotion energy and atmosphere to every scene unlike doge yetio \\u2019 s tokenomics model distributes 50 of yetio to presale 15 to playtoearn reward and 15 to community reward with the rest allocated to burn the project team liquidity and marketing doge v yetio where should you hedge your bet compared to doge yetio is the better choice because of it utilitydriven playtoearn platform and restricted token supply unlike doge volatile price yetio tokenomics with mechanism to burn may drive value higher early presale price also give more potential for upside compared to the established market cap value of doge investor need to be vigilant regarding the untested record of yetio and the overall volatility of cryptocurrency investment join the yeti ouro community website x formerly twitter telegram discord disclaimer this is a sponsored article and is for informational purpose only it doe not reflect the view of crypto daily nor is it intended to be used a legal tax investment or financial advice\",\n          \"could btc maintain above 80k amid weak market condition and accumulation trend . a bitcoin btc navigates turbulent market condition it ability to maintain stability above the 80000 mark raise critical question despite sign of waning retail interest significant whale accumulation ha been\",\n          \"3 crypto favorite this week btc xrp and solana surging . crypto portfolio in 2025 are being built with one goal in mind\\u2014sixfigure result for smart investor magacoinfinance ripple xrp and bitcoin btc are forming the core of that strategy each brings something unique but only one is offering rare earlystage access with true explosive potential bitcoin btc xrp and ethereum eth lay the foundation\\u2014magacoinfinance delivers the acceleration bitcoin btc remains the gold standard in crypto ethereum eth lead web3 innovation and xrp is positioned a a top solution for global payment but trader looking to multiply smaller stack are now focused on magacoinfinance where roi is soaring well beyond what these legacy token can currently match presale selling out \\u2013 click here to secure a spot now magacoinfinance \\u2013 53 million raised 75x potential still in play unprecedented growth potential magacoinfinance ha surpassed 53 million in it limitedsupply presale with 100 billion token locked in and a surge of new buyer the setup is ideal for early growth and longterm momentum use maga50x and get a 50 bonus \\u2013 roi up to 3782 the presale price is 00002704 with a listing price of 0007 giving a 2488 roi or 2588x when you activate maga50x the entry drop to 00001803 delivering 3782 roi or 3782x a 2650 entry could realistically grow to over 100000 by listing\\u2014before any postlaunch runup limited time offerget 50 extra bonus with maga50x xrp ton avax and link longterm project but magacoinfinance lead for roi ripple xrp trade at 075 gaining renewed attention toncoin ton hold at 549 growing via telegram integration avalanche avax trade at 4592 thriving in dapp development chainlink link sits at 1384 powering onchain data accuracy click here to join the next billion dollar project conclusion a the cryptocurrency market continues to evolve both established and emerging digital asset present unique opportunity while bitcoin btc ripple xrp and solana sol pursue growth strategy magacoinfinance distinguishes itself with it innovative approach and attractive presale incentive investor are encouraged to conduct thorough research stay informed about market trend and consider diversifying their portfolio to navigate this dynamic landscape effectively for more information on magacoinfinance and to participate in the presale visit website magacoinfinancecom twitterx the post 3 crypto favorite this week btc xrp and solana surging appeared first on thecoinrisecom\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "test_set_path = os.path.join(PREPROCESSED_DATA_DIR, \"coindesk_test.csv\")\n",
        "train_set_path = os.path.join(PREPROCESSED_DATA_DIR, \"coindesk_train.csv\")\n",
        "val_set_path = os.path.join(PREPROCESSED_DATA_DIR, \"coindesk_val.csv\")\n",
        "\n",
        "train_df = pd.read_csv(train_set_path)\n",
        "val_df = pd.read_csv(val_set_path)\n",
        "test_df = pd.read_csv(test_set_path)\n",
        "\n",
        "df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBQXWLLyDek8"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = train_df['full_text'].values, train_df['label'].values\n",
        "train_dataset = NewsDataset(X_train, y_train, tokenizer)\n",
        "\n",
        "X_val, y_val = val_df['full_text'].values, val_df['label'].values\n",
        "val_dataset = NewsDataset(X_val, y_val, tokenizer)\n",
        "\n",
        "X_test, y_test = test_df['full_text'].values, test_df['label'].values\n",
        "test_dataset = NewsDataset(X_test, y_test, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZunF5dmDek8"
      },
      "source": [
        " ## Calculate class weights to handle imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49bhWBh0Dek9"
      },
      "outputs": [],
      "source": [
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_df['label']),\n",
        "    y=train_df['label']\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90XJ2rh7Dek9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "6f14f1a0-84fc-4768-9847-c6d49b0c2d0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      class    weight\n",
              "0  Negative  1.489287\n",
              "1   Neutral  1.278170\n",
              "2  Positive  0.646760"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d72b0642-fac8-4112-a153-bc6c24dad8a8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Negative</td>\n",
              "      <td>1.489287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>1.278170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Positive</td>\n",
              "      <td>0.646760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d72b0642-fac8-4112-a153-bc6c24dad8a8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d72b0642-fac8-4112-a153-bc6c24dad8a8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d72b0642-fac8-4112-a153-bc6c24dad8a8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-386acb5d-133b-4981-8495-623bf37132d8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-386acb5d-133b-4981-8495-623bf37132d8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-386acb5d-133b-4981-8495-623bf37132d8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f74cf61b-60bc-4f58-ba51-c2eb81c439ca\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_class_weights')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f74cf61b-60bc-4f58-ba51-c2eb81c439ca button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_class_weights');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_class_weights",
              "summary": "{\n  \"name\": \"df_class_weights\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Negative\",\n          \"Neutral\",\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.4892874956130981,\n          1.2781697511672974,\n          0.6467596888542175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "classes = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "weights_np = class_weights.cpu().numpy()\n",
        "\n",
        "df_class_weights = pd.DataFrame({\n",
        "    \"class\": classes,\n",
        "    \"weight\": weights_np\n",
        "})\n",
        "\n",
        "df_class_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpJbZKMDDek-"
      },
      "source": [
        " ## Create weighted trainer\n",
        "\n",
        " REF: https://discuss.huggingface.co/t/how-can-i-use-class-weights-when-training/1067/7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9c3q0NxDek_"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    def __init__(self, *args, class_weights=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def create_optimizer_and_scheduler(self, num_training_steps: int):\n",
        "        # 1. set up AdamW with decoupled weight decay\n",
        "        self.optimizer = AdamW(\n",
        "            self.model.parameters(),\n",
        "            lr=self.args.learning_rate,\n",
        "            weight_decay=self.args.weight_decay,\n",
        "            betas=(0.9, 0.999),\n",
        "            eps=1e-8\n",
        "        )\n",
        "\n",
        "        # 2. linear warmup + decay scheduler\n",
        "        self.lr_scheduler = get_linear_schedule_with_warmup(\n",
        "            self.optimizer,\n",
        "            num_warmup_steps=self.args.warmup_steps,\n",
        "            num_training_steps=num_training_steps\n",
        "        )\n",
        "\n",
        "        return self.optimizer, self.lr_scheduler\n",
        "\n",
        "    # function necessary to consider the computed weights\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=self.class_weights)\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZaoZqoRDelA"
      },
      "source": [
        " ## Hyperparameter Tuning with Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYPpo2LvDelA"
      },
      "outputs": [],
      "source": [
        "def compute_objective(metrics):\n",
        "    # return metrics[\"accuracy\"] * 0.7 + metrics[\"f1\"] * 0.3\n",
        "    return metrics[\"eval_accuracy\"] * 0.7 + metrics[\"eval_f1\"] * 0.3\n",
        "\n",
        "def _compute_metrics(eval_pred: EvalPrediction):\n",
        "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return compute_metrics(preds, labels)\n",
        "\n",
        "def optuna_hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-4, log=True),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.001, 0.1, log=True),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 24, 32]),\n",
        "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.05, 0.2),\n",
        "        \"hidden_dropout_prob\": trial.suggest_float(\"hidden_dropout_prob\", 0.1, 0.5),\n",
        "        \"attention_probs_dropout_prob\": trial.suggest_float(\"attention_probs_dropout_prob\", 0.1, 0.5),\n",
        "    }\n",
        "\n",
        "def model_init(trial):\n",
        "    return AutoModelForSequenceClassification.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        num_labels=NUM_LABELS,\n",
        "        hidden_dropout_prob=trial.params.get(\"hidden_dropout_prob\", 0.3),\n",
        "        attention_probs_dropout_prob=trial.params.get(\"attention_probs_dropout_prob\", 0.3)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FivnvvHyDelB"
      },
      "outputs": [],
      "source": [
        "def run_optuna_optimization():\n",
        "    base_training_args = TrainingArguments(\n",
        "        output_dir=os.path.join(EXPORT_MODEL_DIR, \"optuna_results\"),\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=1,\n",
        "        num_train_epochs=2,  # shorter epochs for tuning\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        report_to=[\"tensorboard\"],\n",
        "        logging_dir=os.path.join(EXPORT_MODEL_DIR, \"logs\"),\n",
        "        logging_steps=50,\n",
        "        metric_for_best_model=\"accuracy\",\n",
        "        load_best_model_at_end=True,\n",
        "        greater_is_better=True,\n",
        "        remove_unused_columns=True,\n",
        "    )\n",
        "\n",
        "    # Using a pruner to terminate unpromising trials early\n",
        "    pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=0)\n",
        "    study = optuna.create_study(\n",
        "        direction=\"maximize\",\n",
        "        sampler=TPESampler(seed=42),\n",
        "        pruner=pruner\n",
        "    )\n",
        "\n",
        "    def optuna_objective(trial):\n",
        "        # Update training arguments with current hyperparameters being explored\n",
        "        hp_params = optuna_hp_space(trial)\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=os.path.join(EXPORT_MODEL_DIR, f\"trial_{trial.number}\"),\n",
        "            eval_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            save_total_limit=1,\n",
        "            learning_rate=hp_params[\"learning_rate\"],\n",
        "            per_device_train_batch_size=hp_params[\"per_device_train_batch_size\"],\n",
        "            per_device_eval_batch_size=hp_params[\"per_device_train_batch_size\"],\n",
        "            num_train_epochs=2,  # shorter epochs for tuning\n",
        "            warmup_ratio=hp_params[\"warmup_ratio\"],\n",
        "            weight_decay=hp_params[\"weight_decay\"],\n",
        "            fp16=torch.cuda.is_available(),\n",
        "            report_to=[\"tensorboard\"],\n",
        "            logging_dir=os.path.join(EXPORT_MODEL_DIR, \"logs\"),\n",
        "            logging_steps=50,\n",
        "            metric_for_best_model=\"accuracy\",\n",
        "            load_best_model_at_end=True,\n",
        "        )\n",
        "\n",
        "        # Initialise model with current hyperparameters\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            MODEL_NAME,\n",
        "            num_labels=NUM_LABELS,\n",
        "            hidden_dropout_prob=hp_params[\"hidden_dropout_prob\"],\n",
        "            attention_probs_dropout_prob=hp_params[\"attention_probs_dropout_prob\"]\n",
        "        ).to(device)\n",
        "\n",
        "        trainer = WeightedTrainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            tokenizer=tokenizer,\n",
        "            compute_metrics=_compute_metrics,\n",
        "            class_weights=class_weights\n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "        eval_results = trainer.evaluate()\n",
        "        objective_value = compute_objective(eval_results)\n",
        "\n",
        "        # Clean up by removing a saved model to free up space on disk\n",
        "        if os.path.exists(os.path.join(EXPORT_MODEL_DIR, f\"trial_{trial.number}\")):\n",
        "            import shutil\n",
        "            shutil.rmtree(os.path.join(EXPORT_MODEL_DIR, f\"trial_{trial.number}\"))\n",
        "\n",
        "        return objective_value\n",
        "\n",
        "    print(\"Starting hyperparameter optimization...\")\n",
        "    study.optimize(optuna_objective, n_trials=15, timeout=None)\n",
        "\n",
        "    print(\"Best hyperparameters:\", study.best_params)\n",
        "    print(\"Best objective value:\", study.best_value)\n",
        "\n",
        "    # Save results\n",
        "    optuna_results_file = os.path.join(EXPORT_MODEL_DIR, \"optuna_study_results.csv\")\n",
        "    study_df = study.trials_dataframe()\n",
        "    study_df.to_csv(optuna_results_file)\n",
        "\n",
        "    # Visualize optimisation results\n",
        "    try:\n",
        "        from optuna.visualization import plot_optimization_history, plot_param_importances\n",
        "\n",
        "        # Plot optimisation history\n",
        "        fig1 = plot_optimization_history(study)\n",
        "        fig1.write_image(os.path.join(EXPORT_MODEL_DIR, \"optuna_history.png\"))\n",
        "\n",
        "        # Plot parameter importances\n",
        "        fig2 = plot_param_importances(study)\n",
        "        fig2.write_image(os.path.join(EXPORT_MODEL_DIR, \"optuna_param_importances.png\"))\n",
        "    except:\n",
        "        print(\"Optuna visualization could not be generated.\")\n",
        "\n",
        "    return study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_pi0yl5DelC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1923300-35af-434c-ffdb-5b8232c4e2aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 05:38:12,141] A new study created in memory with name: no-name-c0c5fffa-acec-449d-96a7-6788e552eb7a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting hyperparameter optimization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-ca0e3f80ddff>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2990' max='2990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2990/2990 06:14, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.810200</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.732932</td>\n",
              "      <td>0.710095</td>\n",
              "      <td>0.732932</td>\n",
              "      <td>0.711176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.675100</td>\n",
              "      <td>0.825662</td>\n",
              "      <td>0.747657</td>\n",
              "      <td>0.732976</td>\n",
              "      <td>0.747657</td>\n",
              "      <td>0.725103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='187' max='187' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [187/187 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 05:44:34,237] Trial 0 finished with value: 0.7408910030855345 and parameters: {'learning_rate': 2.368863950364079e-05, 'weight_decay': 0.07969454818643935, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.05871254182522992, 'hidden_dropout_prob': 0.4464704583099741, 'attention_probs_dropout_prob': 0.34044600469728353}. Best is trial 0 with value: 0.7408910030855345.\n",
            "<ipython-input-26-ca0e3f80ddff>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2990' max='2990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2990/2990 06:11, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.572100</td>\n",
              "      <td>0.542833</td>\n",
              "      <td>0.809906</td>\n",
              "      <td>0.806003</td>\n",
              "      <td>0.809906</td>\n",
              "      <td>0.806741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.404600</td>\n",
              "      <td>0.627077</td>\n",
              "      <td>0.825971</td>\n",
              "      <td>0.820624</td>\n",
              "      <td>0.825971</td>\n",
              "      <td>0.821811</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='187' max='187' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [187/187 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 05:50:53,599] Trial 1 finished with value: 0.8247228211476997 and parameters: {'learning_rate': 5.105903209394759e-05, 'weight_decay': 0.0010994335574766201, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.07751067647801507, 'hidden_dropout_prob': 0.2216968971838151, 'attention_probs_dropout_prob': 0.3099025726528951}. Best is trial 1 with value: 0.8247228211476997.\n",
            "<ipython-input-26-ca0e3f80ddff>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2990' max='2990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2990/2990 06:15, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.764200</td>\n",
              "      <td>0.758598</td>\n",
              "      <td>0.766399</td>\n",
              "      <td>0.750888</td>\n",
              "      <td>0.766399</td>\n",
              "      <td>0.749347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.614300</td>\n",
              "      <td>0.812460</td>\n",
              "      <td>0.789826</td>\n",
              "      <td>0.780904</td>\n",
              "      <td>0.789826</td>\n",
              "      <td>0.779332</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='187' max='187' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [187/187 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 05:57:17,000] Trial 2 finished with value: 0.7866776357418821 and parameters: {'learning_rate': 2.703616066662e-05, 'weight_decay': 0.0038234752246751854, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.1184104976325554, 'hidden_dropout_prob': 0.41407038455720546, 'attention_probs_dropout_prob': 0.1798695128633439}. Best is trial 1 with value: 0.8247228211476997.\n",
            "<ipython-input-26-ca0e3f80ddff>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1496' max='1496' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1496/1496 04:31, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.111500</td>\n",
              "      <td>1.040091</td>\n",
              "      <td>0.591700</td>\n",
              "      <td>0.543453</td>\n",
              "      <td>0.591700</td>\n",
              "      <td>0.521165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.911500</td>\n",
              "      <td>0.931660</td>\n",
              "      <td>0.566265</td>\n",
              "      <td>0.694223</td>\n",
              "      <td>0.566265</td>\n",
              "      <td>0.578888</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='94' max='94' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [94/94 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 06:01:55,692] Trial 3 finished with value: 0.5705395269860406 and parameters: {'learning_rate': 3.267641765781762e-05, 'weight_decay': 0.015304852121831466, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.192332830588, 'hidden_dropout_prob': 0.4862528132298237, 'attention_probs_dropout_prob': 0.4233589392465845}. Best is trial 1 with value: 0.8247228211476997.\n",
            "<ipython-input-26-ca0e3f80ddff>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2990' max='2990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2990/2990 06:10, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.856100</td>\n",
              "      <td>0.743170</td>\n",
              "      <td>0.734940</td>\n",
              "      <td>0.716109</td>\n",
              "      <td>0.734940</td>\n",
              "      <td>0.713032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.750900</td>\n",
              "      <td>0.927028</td>\n",
              "      <td>0.751673</td>\n",
              "      <td>0.738633</td>\n",
              "      <td>0.751673</td>\n",
              "      <td>0.724630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='187' max='187' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [187/187 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 06:08:13,983] Trial 4 finished with value: 0.7435602024061518 and parameters: {'learning_rate': 2.0165721691808572e-05, 'weight_decay': 0.0015679933916723015, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.05515827816728276, 'hidden_dropout_prob': 0.4637281608315128, 'attention_probs_dropout_prob': 0.20351199264000677}. Best is trial 1 with value: 0.8247228211476997.\n",
            "<ipython-input-26-ca0e3f80ddff>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='748' max='748' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [748/748 03:40, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.126800</td>\n",
              "      <td>1.109339</td>\n",
              "      <td>0.281794</td>\n",
              "      <td>0.515308</td>\n",
              "      <td>0.281794</td>\n",
              "      <td>0.199908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.111300</td>\n",
              "      <td>1.097004</td>\n",
              "      <td>0.433735</td>\n",
              "      <td>0.470374</td>\n",
              "      <td>0.433735</td>\n",
              "      <td>0.386349</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [47/47 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 06:12:02,753] Trial 5 finished with value: 0.41951919857777425 and parameters: {'learning_rate': 4.5975057847321686e-05, 'weight_decay': 0.004201672054372531, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.1662699235041672, 'hidden_dropout_prob': 0.4757995766256756, 'attention_probs_dropout_prob': 0.4579309401710595}. Best is trial 1 with value: 0.8247228211476997.\n",
            "<ipython-input-26-ca0e3f80ddff>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='748' max='748' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [748/748 03:43, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.582000</td>\n",
              "      <td>0.534340</td>\n",
              "      <td>0.814592</td>\n",
              "      <td>0.816561</td>\n",
              "      <td>0.814592</td>\n",
              "      <td>0.815302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.469700</td>\n",
              "      <td>0.595608</td>\n",
              "      <td>0.818608</td>\n",
              "      <td>0.812440</td>\n",
              "      <td>0.818608</td>\n",
              "      <td>0.813350</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [47/47 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 06:15:54,047] Trial 6 finished with value: 0.8170303417009869 and parameters: {'learning_rate': 3.961867790406586e-05, 'weight_decay': 0.06978281265126034, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.10830159345342232, 'hidden_dropout_prob': 0.20853961270955837, 'attention_probs_dropout_prob': 0.43149500366077176}. Best is trial 1 with value: 0.8247228211476997.\n",
            "<ipython-input-26-ca0e3f80ddff>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='998' max='998' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [998/998 03:57, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.728000</td>\n",
              "      <td>0.705672</td>\n",
              "      <td>0.783133</td>\n",
              "      <td>0.774852</td>\n",
              "      <td>0.783133</td>\n",
              "      <td>0.776560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.654400</td>\n",
              "      <td>0.823970</td>\n",
              "      <td>0.777108</td>\n",
              "      <td>0.768585</td>\n",
              "      <td>0.777108</td>\n",
              "      <td>0.766399</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 06:19:59,940] Trial 7 finished with value: 0.7811608633778016 and parameters: {'learning_rate': 2.2738055735631803e-05, 'weight_decay': 0.0036464395589807202, 'per_device_train_batch_size': 24, 'warmup_ratio': 0.19803304049007764, 'hidden_dropout_prob': 0.40889790771866297, 'attention_probs_dropout_prob': 0.17948627261366898}. Best is trial 1 with value: 0.8247228211476997.\n",
            "<ipython-input-26-ca0e3f80ddff>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='998' max='998' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [998/998 03:56, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.576400</td>\n",
              "      <td>0.600181</td>\n",
              "      <td>0.804552</td>\n",
              "      <td>0.799159</td>\n",
              "      <td>0.804552</td>\n",
              "      <td>0.800599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.546900</td>\n",
              "      <td>0.607449</td>\n",
              "      <td>0.805890</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.805890</td>\n",
              "      <td>0.801886</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 06:24:03,886] Trial 8 finished with value: 0.8046888675103994 and parameters: {'learning_rate': 1.012796325733148e-05, 'weight_decay': 0.04274869455295218, 'per_device_train_batch_size': 24, 'warmup_ratio': 0.1037698592816409, 'hidden_dropout_prob': 0.1463476238100519, 'attention_probs_dropout_prob': 0.4452413703502375}. Best is trial 1 with value: 0.8247228211476997.\n",
            "<ipython-input-26-ca0e3f80ddff>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='748' max='748' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [748/748 03:42, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.115300</td>\n",
              "      <td>1.073684</td>\n",
              "      <td>0.500669</td>\n",
              "      <td>0.582119</td>\n",
              "      <td>0.500669</td>\n",
              "      <td>0.514549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.897400</td>\n",
              "      <td>0.976482</td>\n",
              "      <td>0.340696</td>\n",
              "      <td>0.741023</td>\n",
              "      <td>0.340696</td>\n",
              "      <td>0.267678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [47/47 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 06:27:53,721] Trial 9 finished with value: 0.504833157498126 and parameters: {'learning_rate': 4.2004723167022006e-05, 'weight_decay': 0.004589824181495649, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.14563362070328198, 'hidden_dropout_prob': 0.4548850970305306, 'attention_probs_dropout_prob': 0.28888597006477973}. Best is trial 1 with value: 0.8247228211476997.\n",
            "<ipython-input-26-ca0e3f80ddff>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1496' max='1496' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1496/1496 04:29, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.720900</td>\n",
              "      <td>0.619934</td>\n",
              "      <td>0.779786</td>\n",
              "      <td>0.782021</td>\n",
              "      <td>0.779786</td>\n",
              "      <td>0.780271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.502600</td>\n",
              "      <td>0.566178</td>\n",
              "      <td>0.803882</td>\n",
              "      <td>0.813175</td>\n",
              "      <td>0.803882</td>\n",
              "      <td>0.806960</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='94' max='94' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [94/94 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 06:32:30,384] Trial 10 finished with value: 0.8048056417138372 and parameters: {'learning_rate': 9.288338406672918e-05, 'weight_decay': 0.0010280029617905613, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.08537422725799389, 'hidden_dropout_prob': 0.2919884385410771, 'attention_probs_dropout_prob': 0.29671335876487964}. Best is trial 1 with value: 0.8247228211476997.\n",
            "<ipython-input-26-ca0e3f80ddff>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='748' max='748' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [748/748 03:43, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.588000</td>\n",
              "      <td>0.505903</td>\n",
              "      <td>0.814592</td>\n",
              "      <td>0.814372</td>\n",
              "      <td>0.814592</td>\n",
              "      <td>0.814460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.427000</td>\n",
              "      <td>0.557593</td>\n",
              "      <td>0.824632</td>\n",
              "      <td>0.821736</td>\n",
              "      <td>0.824632</td>\n",
              "      <td>0.822863</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [47/47 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 06:36:21,148] Trial 11 finished with value: 0.8241011303125932 and parameters: {'learning_rate': 7.327169449875371e-05, 'weight_decay': 0.018877457901429077, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.08618438339248478, 'hidden_dropout_prob': 0.2079085005117408, 'attention_probs_dropout_prob': 0.3623646011031012}. Best is trial 1 with value: 0.8247228211476997.\n",
            "<ipython-input-26-ca0e3f80ddff>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2990' max='2990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2990/2990 06:17, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.098900</td>\n",
              "      <td>1.078548</td>\n",
              "      <td>0.275770</td>\n",
              "      <td>0.267763</td>\n",
              "      <td>0.275770</td>\n",
              "      <td>0.138810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.727100</td>\n",
              "      <td>0.717680</td>\n",
              "      <td>0.712182</td>\n",
              "      <td>0.720105</td>\n",
              "      <td>0.712182</td>\n",
              "      <td>0.714584</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='187' max='187' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [187/187 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 06:42:46,892] Trial 12 finished with value: 0.7129027209464767 and parameters: {'learning_rate': 7.62904672613948e-05, 'weight_decay': 0.017029437058373485, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.07999096688349955, 'hidden_dropout_prob': 0.24937989204002747, 'attention_probs_dropout_prob': 0.3579072302663711}. Best is trial 1 with value: 0.8247228211476997.\n",
            "<ipython-input-26-ca0e3f80ddff>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='748' max='748' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [748/748 03:42, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.540300</td>\n",
              "      <td>0.504026</td>\n",
              "      <td>0.807898</td>\n",
              "      <td>0.809912</td>\n",
              "      <td>0.807898</td>\n",
              "      <td>0.808726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.318100</td>\n",
              "      <td>0.532915</td>\n",
              "      <td>0.831995</td>\n",
              "      <td>0.830112</td>\n",
              "      <td>0.831995</td>\n",
              "      <td>0.830924</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [47/47 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 06:46:36,867] Trial 13 finished with value: 0.8316735447249012 and parameters: {'learning_rate': 6.229801415331804e-05, 'weight_decay': 0.02665262919639136, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.08269115363959155, 'hidden_dropout_prob': 0.1200830393113325, 'attention_probs_dropout_prob': 0.24727497246201913}. Best is trial 13 with value: 0.8316735447249012.\n",
            "<ipython-input-26-ca0e3f80ddff>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='748' max='748' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [748/748 03:43, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.531200</td>\n",
              "      <td>0.495364</td>\n",
              "      <td>0.823963</td>\n",
              "      <td>0.823312</td>\n",
              "      <td>0.823963</td>\n",
              "      <td>0.823620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.307500</td>\n",
              "      <td>0.534493</td>\n",
              "      <td>0.831325</td>\n",
              "      <td>0.831275</td>\n",
              "      <td>0.831325</td>\n",
              "      <td>0.831122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [47/47 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 06:50:27,697] Trial 14 finished with value: 0.8312642264936824 and parameters: {'learning_rate': 5.904093948077807e-05, 'weight_decay': 0.03446511659889725, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.1363265218734974, 'hidden_dropout_prob': 0.11940552246951587, 'attention_probs_dropout_prob': 0.10965592371923005}. Best is trial 13 with value: 0.8316735447249012.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'learning_rate': 6.229801415331804e-05, 'weight_decay': 0.02665262919639136, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.08269115363959155, 'hidden_dropout_prob': 0.1200830393113325, 'attention_probs_dropout_prob': 0.24727497246201913}\n",
            "Best objective value: 0.8316735447249012\n",
            "Optuna visualization could not be generated. This usually requires plotly.\n"
          ]
        }
      ],
      "source": [
        "best_params = run_optuna_optimization()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1IQFYBiDelD"
      },
      "source": [
        " ## Training with the Best Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9nEO2exDelD"
      },
      "outputs": [],
      "source": [
        "def train_with_best_params(best_params):\n",
        "    # Initialise model with best hyperparameters\n",
        "    best_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        num_labels=NUM_LABELS,\n",
        "        hidden_dropout_prob=best_params.get(\"hidden_dropout_prob\", 0.3),\n",
        "        attention_probs_dropout_prob=best_params.get(\"attention_probs_dropout_prob\", 0.3)\n",
        "    ).to(device)\n",
        "\n",
        "    best_training_args = TrainingArguments(\n",
        "        output_dir=os.path.join(EXPORT_MODEL_DIR, \"best_model\"),\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=2,\n",
        "        learning_rate=best_params.get(\"learning_rate\", 5e-5),\n",
        "        per_device_train_batch_size=best_params.get(\"per_device_train_batch_size\", 16),\n",
        "        per_device_eval_batch_size=best_params.get(\"per_device_train_batch_size\", 16),\n",
        "        num_train_epochs=NUM_EPOCHS,  # Full training with best params\n",
        "        warmup_ratio=best_params.get(\"warmup_ratio\", 0.1),\n",
        "        weight_decay=best_params.get(\"weight_decay\", 0.01),\n",
        "        metric_for_best_model=\"accuracy\",\n",
        "        load_best_model_at_end=True,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        report_to=[\"tensorboard\"],\n",
        "        logging_dir=os.path.join(EXPORT_MODEL_DIR, \"logs\"),\n",
        "        logging_steps=50,\n",
        "    )\n",
        "\n",
        "    best_trainer = WeightedTrainer(\n",
        "        model=best_model,\n",
        "        args=best_training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=_compute_metrics,\n",
        "        class_weights=class_weights\n",
        "    )\n",
        "\n",
        "    best_trainer.train()\n",
        "\n",
        "    best_model_path = os.path.join(EXPORT_MODEL_DIR, \"best_model_final\")\n",
        "    best_trainer.save_model(best_model_path)\n",
        "    tokenizer.save_pretrained(best_model_path)\n",
        "\n",
        "    return best_trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYPIRtWnDelE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "a1c0e373-bc23-43c0-f475-38ffac339f42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with best hyperparameters: {'learning_rate': 6.229801415331804e-05, 'weight_decay': 0.02665262919639136, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.08269115363959155, 'hidden_dropout_prob': 0.1200830393113325, 'attention_probs_dropout_prob': 0.24727497246201913}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-ca0e3f80ddff>:6: FutureWarning:\n",
            "\n",
            "`tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1122' max='1122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1122/1122 05:36, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.551100</td>\n",
              "      <td>0.514004</td>\n",
              "      <td>0.813253</td>\n",
              "      <td>0.809823</td>\n",
              "      <td>0.813253</td>\n",
              "      <td>0.811213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.336200</td>\n",
              "      <td>0.533320</td>\n",
              "      <td>0.829317</td>\n",
              "      <td>0.825244</td>\n",
              "      <td>0.829317</td>\n",
              "      <td>0.826469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.200500</td>\n",
              "      <td>0.640562</td>\n",
              "      <td>0.831995</td>\n",
              "      <td>0.829658</td>\n",
              "      <td>0.831995</td>\n",
              "      <td>0.830634</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer = train_with_best_params(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IppDETtBDelG"
      },
      "source": [
        " ## Evaluate on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOcbPmYmDelG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "3deaa6de-7734-4e2e-83c2-f3ce909cf94a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='94' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [47/47 00:27]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.6448201537132263,\n",
              " 'eval_accuracy': 0.8247491638795986,\n",
              " 'eval_precision': 0.8205826754509884,\n",
              " 'eval_recall': 0.8247491638795986,\n",
              " 'eval_f1': 0.8217456269144716,\n",
              " 'eval_runtime': 5.9268,\n",
              " 'eval_samples_per_second': 252.242,\n",
              " 'eval_steps_per_second': 7.93,\n",
              " 'epoch': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "test_results = trainer.evaluate(test_dataset)\n",
        "test_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMBMbvX5DelG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "248b34d1-0ddf-47ec-d674-0a17c0ec7386"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.85      0.83       335\n",
            "           1       0.72      0.64      0.67       390\n",
            "           2       0.87      0.91      0.89       770\n",
            "\n",
            "    accuracy                           0.82      1495\n",
            "   macro avg       0.80      0.80      0.80      1495\n",
            "weighted avg       0.82      0.82      0.82      1495\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "print(classification_report(y_test, predicted_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_4J4vVODelI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "d18eef62-c2cc-4afb-c201-75ca3487f2e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fea9c511bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test, predicted_labels)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwcAlGsVDelI"
      },
      "source": [
        " ## Compare with different hyperparameter sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPXD59bUDelK"
      },
      "outputs": [],
      "source": [
        "def compare_hyperparameter_sets():\n",
        "    # The hyperparameter sets to compare\n",
        "    hp_sets = [\n",
        "        {\"name\": \"Default\", \"lr\": 5e-5, \"wd\": 0.01, \"bs\": 16, \"dropout\": 0.3},\n",
        "        {\"name\": \"Higher LR\", \"lr\": 1e-4, \"wd\": 0.01, \"bs\": 16, \"dropout\": 0.3},\n",
        "        {\"name\": \"Higher Dropout\", \"lr\": 5e-5, \"wd\": 0.01, \"bs\": 16, \"dropout\": 0.5},\n",
        "        {\"name\": \"Larger Batch\", \"lr\": 5e-5, \"wd\": 0.01, \"bs\": 32, \"dropout\": 0.3},\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "    for hp_set in hp_sets:\n",
        "        print(f\"\\nTraining with {hp_set['name']} configuration...\")\n",
        "\n",
        "        hp_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            MODEL_NAME,\n",
        "            num_labels=NUM_LABELS,\n",
        "            hidden_dropout_prob=hp_set[\"dropout\"],\n",
        "            attention_probs_dropout_prob=hp_set[\"dropout\"]\n",
        "        ).to(device)\n",
        "\n",
        "        hp_training_args = TrainingArguments(\n",
        "            output_dir=os.path.join(EXPORT_MODEL_DIR, f\"compare_{hp_set['name']}\"),\n",
        "            eval_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            save_total_limit=1,\n",
        "            learning_rate=hp_set[\"lr\"],\n",
        "            per_device_train_batch_size=hp_set[\"bs\"],\n",
        "            per_device_eval_batch_size=hp_set[\"bs\"],\n",
        "            num_train_epochs=2,  # shorter for comparison\n",
        "            warmup_ratio=0.1,\n",
        "            weight_decay=hp_set[\"wd\"],\n",
        "            metric_for_best_model=\"accuracy\",\n",
        "            load_best_model_at_end=True,\n",
        "            fp16=torch.cuda.is_available(),\n",
        "            report_to=[\"tensorboard\"],\n",
        "            logging_dir=os.path.join(EXPORT_MODEL_DIR, \"logs\"),\n",
        "            logging_steps=50,\n",
        "        )\n",
        "\n",
        "        hp_trainer = WeightedTrainer(\n",
        "            model=hp_model,\n",
        "            args=hp_training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            tokenizer=tokenizer,\n",
        "            compute_metrics=_compute_metrics,\n",
        "            class_weights=class_weights\n",
        "        )\n",
        "\n",
        "        hp_trainer.train()\n",
        "        eval_results = hp_trainer.evaluate()\n",
        "\n",
        "        # Save results\n",
        "        results.append({\n",
        "            \"config\": hp_set[\"name\"],\n",
        "            \"accuracy\": eval_results[\"eval_accuracy\"],\n",
        "            \"f1\": eval_results[\"eval_f1\"],\n",
        "            \"loss\": eval_results[\"eval_loss\"]\n",
        "        })\n",
        "\n",
        "        # Clean up\n",
        "        import shutil\n",
        "        if os.path.exists(os.path.join(EXPORT_MODEL_DIR, f\"compare_{hp_set['name']}\")):\n",
        "            shutil.rmtree(os.path.join(EXPORT_MODEL_DIR, f\"compare_{hp_set['name']}\"))\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(\"\\nHyperparameter Comparison Results:\")\n",
        "    print(results_df)\n",
        "\n",
        "    # Plot results (accuracy, F1 score, loss...)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    ax1 = plt.subplot(1, 2, 1)\n",
        "    results_df.plot(x=\"config\", y=[\"accuracy\", \"f1\"], kind=\"bar\", ax=ax1)\n",
        "    ax1.set_title(\"Accuracy and F1 Score\")\n",
        "    ax1.set_ylabel(\"Score\")\n",
        "    ax1.set_ylim(0, 1)\n",
        "\n",
        "    ax2 = plt.subplot(1, 2, 2)\n",
        "    results_df.plot(x=\"config\", y=[\"loss\"], kind=\"bar\", ax=ax2, color=\"red\")\n",
        "    ax2.set_title(\"Validation Loss\")\n",
        "    ax2.set_ylabel(\"Loss\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(EXPORT_MODEL_DIR, \"hyperparameter_comparison.png\"))\n",
        "    plt.show()\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# compare_results = compare_hyperparameter_sets()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}